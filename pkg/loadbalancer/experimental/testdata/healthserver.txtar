#! --enable-experimental-lb --enable-health-check-nodeport --lb-test-fault-probability=0.0

# Start and wait for initialization.
hive start
db/initialized

# Replace the port numbers
replace '$PORT1' $PORT1 service.yaml
replace '$PORT2' $PORT2 service2.yaml
replace '$PORT1' $PORT1 services.table
replace '$PORT1' $PORT1 health_with_service.table
replace '$PORT' $PORT1 frontends.table
replace '$PORT' $PORT1 backends.table
replace '$PORT' $PORT1 lbmaps.expected

# HealthServer's jobs should be reported in module health
db/cmp --grep=^loadbalancer health health_no_service.table

# Add a node address, service and endpoints.
db/insert node-addresses addrv4.yaml
db/cmp node-addresses nodeaddrs.table
k8s add service.yaml endpointslice.yaml
db/cmp services services.table
db/cmp frontends frontends.table
db/cmp backends backends.table 

# Check the BPF maps
lb/maps-dump lbmaps.actual
* cmp lbmaps.expected lbmaps.actual

# HealthServer's job should now report a server running
db/cmp --grep=^loadbalancer health health_with_service.table

# Validate health server response
* http/get http://127.0.0.88:$PORT1 healthserver.actual
cmp healthserver.expected healthserver.actual

# Test changing the health check port
k8s update service2.yaml

# Check that $PORT2 now responds and old port does not.
* http/get http://127.0.0.88:$PORT2 healthserver.actual
cmp healthserver.expected healthserver.actual
! http/get http://127.0.0.88:$PORT1 healthserver.actual

# Check that the frontend for the health server is updated
replace $PORT1 $PORT2 frontends.table
db/cmp frontends frontends.table
replace $PORT1 $PORT2 backends.table
db/cmp backends backends.table

# Test removing the health check port
k8s update service_no_port.yaml

# Both ports should now stop responding
# "!*" means expect failure and retry if needed
!* http/get http://127.0.0.88:$PORT2 healthserver.actual
!* http/get http://127.0.0.88:$PORT1 healthserver.actual

db/cmp frontends frontends_nohealthcheck.table
db/cmp backends backends_nohealthcheck.table

#####

-- addrv4.yaml --
addr: 1.1.1.1
nodeport: true
primary: true
devicename: test

-- health_no_service.table --
Module                                   Component                   Level   Message                    Error   
loadbalancer-experimental.healthserver   job-control-loop            OK      0 health servers running   
loadbalancer-experimental.reconciler     job-reconcile               OK      OK, 0 object(s)            
loadbalancer-experimental.reconciler     job-refresh                 OK      Next refresh in 30m0s      
loadbalancer-experimental.reflector      job-reflector               OK      Running                    

-- health_with_service.table --
Module                                   Component                   Level   Message                    Error   
loadbalancer-experimental.healthserver   job-control-loop            OK      1 health servers running   
loadbalancer-experimental.healthserver   job-listener-$PORT1          OK      Running
loadbalancer-experimental.reconciler     job-reconcile               OK      OK, 3 object(s)            
loadbalancer-experimental.reconciler     job-refresh                 OK      Next refresh in 30m0s      
loadbalancer-experimental.reflector      job-reflector               OK      Running                    

-- nodeaddrs.table --
Address NodePort Primary DeviceName
1.1.1.1 true     true    test

-- services.table --
Name         Source   NatPolicy   ExtTrafficPolicy   IntTrafficPolicy   SessionAffinity   HealthCheckNodePort   LoopbackHostPort   SourceRanges
test/echo    k8s                  Local              Local                                $PORT1                 false

-- frontends.table --
Address               Type        ServiceName            PortName   Status  Backends
0.0.0.0:30781/TCP     NodePort    test/echo              http       Done    10.244.1.1:80/TCP (active), 10.244.1.2:80/TCP (active), 10.244.1.3:80/TCP (active), 10.244.1.4:80/TCP (active)
0.0.0.0:$PORT/TCP     NodePort    test/echo-healthserver            Done    127.0.0.88:$PORT/TCP/i (active)
10.96.50.104:80/TCP   ClusterIP   test/echo              http       Done    10.244.1.1:80/TCP (active), 10.244.1.2:80/TCP (active), 10.244.1.3:80/TCP (active), 10.244.1.4:80/TCP (active)

-- frontends_nohealthcheck.table --
Address               Type        ServiceName            PortName   Status  Backends
0.0.0.0:30781/TCP     NodePort    test/echo              http       Done    10.244.1.1:80/TCP (active), 10.244.1.2:80/TCP (active), 10.244.1.3:80/TCP (active), 10.244.1.4:80/TCP (active)
10.96.50.104:80/TCP   ClusterIP   test/echo              http       Done    10.244.1.1:80/TCP (active), 10.244.1.2:80/TCP (active), 10.244.1.3:80/TCP (active), 10.244.1.4:80/TCP (active)

-- frontends_empty.table --
Address               Type        ServiceName   PortName   Status  Backends

-- backends.table --
Address                State    Instances              NodeName     ZoneID
10.244.1.1:80/TCP      active   test/echo (http)       testnode     0
10.244.1.2:80/TCP      active   test/echo (http)       testnode     0
10.244.1.3:80/TCP      active   test/echo (http)       othernode    0
10.244.1.4:80/TCP      active   test/echo (http)       othernode    0
127.0.0.88:$PORT/TCP/i active   test/echo-healthserver testnode     0

-- backends_nohealthcheck.table --
Address               State    Instances              NodeName     ZoneID
10.244.1.1:80/TCP     active   test/echo (http)       testnode     0
10.244.1.2:80/TCP     active   test/echo (http)       testnode     0
10.244.1.3:80/TCP     active   test/echo (http)       othernode    0
10.244.1.4:80/TCP     active   test/echo (http)       othernode    0

-- backends_empty.table --
Address             State    Instances            NodeName           ZoneID

-- service.yaml --
apiVersion: v1
kind: Service
metadata:
  creationTimestamp: "2022-09-13T11:11:26Z"
  name: echo
  namespace: test
  resourceVersion: "741"
  uid: a49fe99c-3564-4754-acc4-780f2331a49b
spec:
  clusterIP: 10.96.50.104
  clusterIPs:
  - 10.96.50.104
  externalTrafficPolicy: Local
  internalTrafficPolicy: Local
  healthCheckNodePort: $PORT1
  ipFamilies:
  - IPv4
  ipFamilyPolicy: SingleStack
  ports:
  - name: http
    nodePort: 30781
    port: 80
    protocol: TCP
    targetPort: 80
  selector:
    name: echo
  sessionAffinity: None
  type: NodePort
status:
  loadBalancer: {}

-- service2.yaml --
apiVersion: v1
kind: Service
metadata:
  creationTimestamp: "2022-09-13T11:11:26Z"
  name: echo
  namespace: test
  resourceVersion: "741"
  uid: a49fe99c-3564-4754-acc4-780f2331a49b
spec:
  clusterIP: 10.96.50.104
  clusterIPs:
  - 10.96.50.104
  externalTrafficPolicy: Local
  internalTrafficPolicy: Local
  healthCheckNodePort: $PORT2
  ipFamilies:
  - IPv4
  ipFamilyPolicy: SingleStack
  ports:
  - name: http
    nodePort: 30781
    port: 80
    protocol: TCP
    targetPort: 80
  selector:
    name: echo
  sessionAffinity: None
  type: NodePort
status:
  loadBalancer: {}

  
-- service_no_port.yaml --
apiVersion: v1
kind: Service
metadata:
  creationTimestamp: "2022-09-13T11:11:26Z"
  name: echo
  namespace: test
  resourceVersion: "741"
  uid: a49fe99c-3564-4754-acc4-780f2331a49b
spec:
  clusterIP: 10.96.50.104
  clusterIPs:
  - 10.96.50.104
  externalTrafficPolicy: Local
  internalTrafficPolicy: Local
  ipFamilies:
  - IPv4
  ipFamilyPolicy: SingleStack
  ports:
  - name: http
    nodePort: 30781
    port: 80
    protocol: TCP
    targetPort: 80
  selector:
    name: echo
  sessionAffinity: None
  type: NodePort
status:
  loadBalancer: {}
  

-- endpointslice.yaml --
apiVersion: discovery.k8s.io/v1
kind: EndpointSlice
metadata:
  annotations:
  creationTimestamp: "2022-09-13T11:11:26Z"
  generateName: echo-
  generation: 3
  labels:
    endpointslice.kubernetes.io/managed-by: endpointslice-controller.k8s.io
    kubernetes.io/service-name: echo
  name: echo-kvlm2
  namespace: test
  resourceVersion: "797"
  uid: d1f517f6-ab88-4c76-9bd0-4906a17cdd75
addressType: IPv4
endpoints:
- addresses:
  - 10.244.1.1
  nodeName: testnode
- addresses:
  - 10.244.1.2
  nodeName: testnode
- addresses:
  - 10.244.1.3
  nodeName: othernode
- addresses:
  - 10.244.1.4
  nodeName: othernode
ports:
- name: http
  port: 80
  protocol: TCP

-- healthserver.expected --
200 OK
Content-Length=66
Content-Type=application/json
Date=<omitted>
X-Content-Type-Options=nosniff
X-Load-Balancing-Endpoint-Weight=2
---
{"service":{"namespace":"test","name":"echo"},"localEndpoints":2}
-- lbmaps.expected --
BE: ID=1 ADDR=10.244.1.1:80 STATE=active
BE: ID=2 ADDR=10.244.1.2:80 STATE=active
BE: ID=3 ADDR=10.244.1.3:80 STATE=active
BE: ID=4 ADDR=10.244.1.4:80 STATE=active
BE: ID=5 ADDR=127.0.0.88:$PORT STATE=active
REV: ID=1 ADDR=10.96.50.104:80
REV: ID=2 ADDR=<zero>
REV: ID=3 ADDR=1.1.1.1:30781
REV: ID=4 ADDR=<zero>
REV: ID=5 ADDR=1.1.1.1:$PORT
SVC: ID=1 ADDR=10.96.50.104:80 SLOT=0 BEID=0 COUNT=4 QCOUNT=0 FLAGS=ClusterIP+Local+InternalLocal+non-routable
SVC: ID=1 ADDR=10.96.50.104:80 SLOT=1 BEID=1 COUNT=0 QCOUNT=0 FLAGS=ClusterIP+Local+InternalLocal+non-routable
SVC: ID=1 ADDR=10.96.50.104:80 SLOT=2 BEID=2 COUNT=0 QCOUNT=0 FLAGS=ClusterIP+Local+InternalLocal+non-routable
SVC: ID=1 ADDR=10.96.50.104:80 SLOT=3 BEID=3 COUNT=0 QCOUNT=0 FLAGS=ClusterIP+Local+InternalLocal+non-routable
SVC: ID=1 ADDR=10.96.50.104:80 SLOT=4 BEID=4 COUNT=0 QCOUNT=0 FLAGS=ClusterIP+Local+InternalLocal+non-routable
SVC: ID=2 ADDR=<zero> SLOT=0 BEID=0 COUNT=4 QCOUNT=0 FLAGS=NodePort+Local+InternalLocal+non-routable
SVC: ID=2 ADDR=<zero> SLOT=1 BEID=1 COUNT=0 QCOUNT=0 FLAGS=NodePort+Local+InternalLocal+non-routable
SVC: ID=2 ADDR=<zero> SLOT=2 BEID=2 COUNT=0 QCOUNT=0 FLAGS=NodePort+Local+InternalLocal+non-routable
SVC: ID=2 ADDR=<zero> SLOT=3 BEID=3 COUNT=0 QCOUNT=0 FLAGS=NodePort+Local+InternalLocal+non-routable
SVC: ID=2 ADDR=<zero> SLOT=4 BEID=4 COUNT=0 QCOUNT=0 FLAGS=NodePort+Local+InternalLocal+non-routable
SVC: ID=3 ADDR=1.1.1.1:30781 SLOT=0 BEID=0 COUNT=4 QCOUNT=0 FLAGS=NodePort+Local+InternalLocal
SVC: ID=3 ADDR=1.1.1.1:30781 SLOT=1 BEID=1 COUNT=0 QCOUNT=0 FLAGS=NodePort+Local+InternalLocal
SVC: ID=3 ADDR=1.1.1.1:30781 SLOT=2 BEID=2 COUNT=0 QCOUNT=0 FLAGS=NodePort+Local+InternalLocal
SVC: ID=3 ADDR=1.1.1.1:30781 SLOT=3 BEID=3 COUNT=0 QCOUNT=0 FLAGS=NodePort+Local+InternalLocal
SVC: ID=3 ADDR=1.1.1.1:30781 SLOT=4 BEID=4 COUNT=0 QCOUNT=0 FLAGS=NodePort+Local+InternalLocal
SVC: ID=4 ADDR=<zero> SLOT=0 BEID=0 COUNT=1 QCOUNT=0 FLAGS=NodePort+Local+InternalLocal+non-routable
SVC: ID=4 ADDR=<zero> SLOT=1 BEID=5 COUNT=0 QCOUNT=0 FLAGS=NodePort+Local+InternalLocal+non-routable
SVC: ID=5 ADDR=1.1.1.1:$PORT SLOT=0 BEID=0 COUNT=1 QCOUNT=0 FLAGS=NodePort+Local+InternalLocal
SVC: ID=5 ADDR=1.1.1.1:$PORT SLOT=1 BEID=5 COUNT=0 QCOUNT=0 FLAGS=NodePort+Local+InternalLocal
